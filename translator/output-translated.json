{
    "1": {
        "text": "10\nCaching with Redis and \nDeployment on Ubuntu \n(DigitalOcean) and Netlify\nIn this chapter, we are going to explore yet another deployment setup – a robust Uvicorn/Gunicorn/Nginx \nsolution that has been tried and tested with Django and other WSGIs but also ASGI web applications. \nThis should give you more than enough choices when starting your next FARM stack project. We will \nalso add a simple caching solution with Redis, relieving MongoDB from some requests that could (and \nshould!) be cached and served directly. Finally, we will deploy our React-based frontend on Netlify, \nanother very popular deployment option, whose simplicity matches its flexibility.\nIn this chapter, we will cover the following topics:\n• Creating an account on DigitalOcean (optional)\n• Preparing our Ubuntu server with Nginx\n• Deployment of a FastAPI instance through Uvicorn, Gunicorn, and Nginx\n• Caching with Redis\n• Creating a free account on Netlify\n• Deployment of the React Frontend on Netlify\nBy the end of this chapter, you should feel confident when it comes to deploying FARM stack-based \napplications on a variety of serving platforms, including a bare-bones Ubuntu (or any Linux) server. \nYou will be able to recognize where and how to add caching and implement it effortlessly with Redis. \nFinally, with the knowledge of possible deployment solutions, you will be able to make solid decisions \nwhen the time comes to deploy your application.\n",
        "img": [],
        "translation": "10\n使用Redis进行缓存和在Ubuntu（DigitalOcean）和Netlify上部署\n在本章中，我们将探索另一种部署设置-一个经过试验和测试用于Django和其他WSGI以及ASGI Web应用程序的强大的Uvicorn/Gunicorn/Nginx解决方案。这应该为您在开始下一个FARM堆栈项目时提供足够的选择。我们还将添加一个简单的Redis缓存解决方案，减轻MongoDB的一些请求，这些请求可以（而且应该！）直接进行缓存并提供。最后，我们将在Netlify上部署基于React的前端，这是另一个非常流行的部署选项，其简单性与其灵活性相匹配。\n在本章中，我们将涵盖以下主题：\n•在DigitalOcean上创建帐户（可选）\n•准备我们的Ubuntu服务器使用Nginx\n•通过Uvicorn、Gunicorn和Nginx部署FastAPI实例\n•使用Redis进行缓存\n•在Netlify上创建一个免费帐户\n•在Netlify上部署React前端\n到本章结束时，您应该在不同的服务平台上部署基于FARM堆栈的应用程序时感到自信，包括裸机的Ubuntu（或任何Linux）服务器。您将能够识别何时何地添加缓存，并轻松地使用Redis实现它。最后，有了可能的部署解决方案的知识，当部署应用程序的时候，您将能够做出坚实的决策。"
    },
    "2": {
        "text": "Caching with Redis and Deployment on Ubuntu (DigitalOcean) and Netlify\n280\nDeploying FastAPI on DigitalOcean (or really any Linux \nserver!)\nIn this section, we are going to take our simple analytics application and deploy it on a Ubuntu \nserver on DigitalOcean (www.digitalocean.com) as an Asynchronous Server Gateway \nInterface (ASGI) application. We are going to end up with a pretty robust and customizable setup \nthat includes our development web server – Uvicorn – but also Gunicorn (https://gunicorn.\norg), an excellent and robust web server that plays very nicely with Nginx, and a virtual machine \nrunning Ubuntu – a DigitalOcean droplet. Though in this example we are going to use DigitalOcean, \nthe procedure should apply to any Debian or Ubuntu-based setup; you can try it out on your own \nmachine running Ubuntu. The following instructions rely heavily on the excellent tutorials on setting \nup an Ubuntu server on DigitalOcean by Brian Boucheron (https://www.digitalocean.\ncom/community/tutorials/initial-server-setup-with-ubuntu-20-04) \nand on deploying an Async Django application by Mason Egger and Erin Glass (https://www.\ndigitalocean.com/community/tutorials/how-to-set-up-an-asgi-django-\napp-with-postgres-nginx-and-uvicorn-on-ubuntu-20-04). You should read them \nas they are very useful and well written!\nImportant Note\nIn this section, we will make heavy use of SSH – the Secure Shell Protocol. SSH is a cryptographic \nprotocol developed for accessing secure network services over insecure networks. If that doesn’t \nmake much sense, do not worry – there are plenty of great resources on basic SSH operations \non the internet. If you are willing to dive a bit deeper into DevOps, you can read the following \nbook: https://www.amazon.com/Mastering-Ubuntu-Server-configuring-\ntroubleshooting/dp/1800564643. Mastering Ubuntu Server is an excellent guide on \nthe subject. In the following pages, we will just log into a DigitalOcean droplet, which is nothing \nmore than a remote Ubuntu computer that we will be able to control. While I will show the \nprocedure for deploying a fully functional FastAPI instance on a DigitalOcean droplet, the best \nway to try out this procedure would be to practice on your Ubuntu-based server. If you have a \nspare box (even an older one), install Ubuntu and try connecting to it from your main computer.\nThe deployment procedure will be broken into easy steps.\nDigitalOcean is one of the leaders in providing cloud computing and Infrastructure as a Service \n(IaaS). Users can benefit from different types of virtual machines that can be modeled according to \nour needs. In our case, we just want a solution for hosting our FastAPI server, similar to how we did \nwith Heroku in the previous chapters.\nWhile DigitalOcean doesn’t provide a completely free tier, it is reasonably cheap to get started (around \n4 USD per month). It has a flexible and scalable system where you can easily scale up or down \naccording to your needs and it offers complete control of the virtual machines – droplets, a fact that \nbrings us a whole new level of flexibility, a word that we often used in this book. Another advantage \n",
        "img": [],
        "translation": "Redis缓存和在Ubuntu（DigitalOcean）和Netlify上部署\n280\n将FastAPI部署到DigitalOcean（或任何Linux服务器！）\n在本节中，我们将把简单的分析应用程序部署在DigitalOcean（www.digitalocean.com）上的Ubuntu服务器上，作为异步服务器网关接口（ASGI）应用程序。我们最终将获得一个相当强大和可定制的设置，其中包括我们的开发Web服务器-Uvicorn，以及Gunicorn（https://gunicorn.org），一个与Nginx非常友好且稳健的Web服务器，并运行Ubuntu的虚拟机-数字海洋水滴。虽然在本例中，我们将使用DigitalOcean，但该过程应该适用于任何基于Debian或Ubuntu的设置；您可以在运行Ubuntu的自己的机器上尝试它。以下说明在Ubuntu上设置DigitalOcean服务器的优秀教程中大力借鉴了Brian Boucheron（https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04）和Mason Egger和Erin Glass部署Async Django应用程序的教程（https://www.digitalocean.com/community/tutorials/how-to-set-up-an-asgi-django-app-with-postgres-nginx-and-uvicorn-on-ubuntu-20-04）。你应该阅读它们，因为它们非常有用且写得很好！\n重要提醒\n在本节中，我们将大量使用SSH-安全外壳协议。 SSH是为在不安全的网络上访问安全网络服务而开发的加密协议。 如果这不太合理，请不要担心-有很多关于基本SSH操作的优秀资源在互联网上。 如果您愿意深入了解DevOps，您可以阅读以下内容：https://www.amazon.com/Mastering-Ubuntu-Server-configuring-troubleshooting/dp/1800564643。掌握Ubuntu服务器是一个优秀的指南。 在以下页面中，我们将只是登录到DigitalOcean droplet，这不过是一个我们将能够控制的远程Ubuntu计算机。 虽然我将展示在DigitalOcean droplet上部署完全功能的FastAPI实例的过程，但尝试此过程的最佳方法是在基于Ubuntu的服务器上练习。 如果您有备用的框（甚至是较旧的框），请安装Ubuntu并尝试从主计算机连接到它。 部署过程将分为简单的步骤。\nDigitalOcean是提供云计算和基础架构即服务（IaaS）的领导者之一。 用户可以从不同类型的虚拟机中受益，这些虚拟机可以根据我们的需要进行建模。 在我们的情况下，我们只是需要一种解决方案来托管我们的FastAPI服务器，类似于在前几章中使用Heroku的方法。\n虽然DigitalOcean没有提供完全免费的层，但起步相当便宜（约4美元/月）。 它具有灵活和可扩展的系统，可以根据您的需求轻松缩放，它提供了对虚拟机-滴答声的完全控制，这也为我们带来了一个全新的灵活性水平，这是我们在本书中经常使用的一个词。 另一个优点"
    },
    "3": {
        "text": "Deploying FastAPI on DigitalOcean (or really any Linux server!)\n281\nof DigitalOcean is its excellent community and an endless list of well-written articles on any service \nor setup you may want to achieve, so it represents a good place to start if you are entering the world of \ndeployment, database setup, and so on. Just to be clear, DigitalOcean, as well as its competitors (Linode, \nfor instance) is perfectly able to host our complete full-stack setup – we could install MongoDB on the \nserver as well, add Node.js and Next or a React frontend, and orchestrate everything through Nginx, \na powerful and fast server. In this example, however, we only want to serve our FastAPI instance and \nshowcase a different type of deployment. Follow these steps:\n1. \nCreate an account on DigitalOcean! Head over to the DigitalOcean signup page at https://\ncloud.digitalocean.com/registrations/new and fill in your data. You can sign \nin with GitHub or Google if you wish, and you can use a referral code if you have one so that \nyou can try out the service for a determined time. Once you submit your data (and once you \nhave some credit to spend – be it from a referral program or after you connect your credit \ncard), you will be able to create your first droplet. \n2. \nCreate a droplet. I have used a Ubuntu 22.04 x64 Ubuntu distribution, the plan is Basic (the \ncheapest), and the CPU options are $4/month with 512 MB/1 CPU (you will have to hit the \nleft arrow to find this plan!). Since I am in Europe, I selected the Frankfurt data center region. \nFinally, to simplify things, I opted for password authentication, so I entered a root password \n(that I am not going to disclose here!). I gave the hostname a name – farmstack. Although \nwe will be using the IP address to access this brand-new machine through SSH, it is useful to \nhave a user-friendly machine name.\nGive DigitalOcean some time to prepare your droplet. After about 30 seconds, you will be able \nto click on the lefthand menu under Droplets and you will be taken to a page that displays \ninformation about your droplet. You now have a Ubuntu-based server under your control! \n3. \nTo verify that you are indeed able to log in as root on your brand-new machine, click on the IP \naddress of the droplet to copy it, open Cmder (or whatever shell you have been using this whole \ntime) on Windows or a bash/shell if you are on Linux or macOS, and try to access the droplet:\nssh root@<your_IP_address_that_you_just_copied>\n4. \nCmder will kindly inform you that the authenticity of the host cannot be established, which is \nnormal at this stage, and ask you if you want to continue connecting. Type yes; you will be \ngreeted with a shell that should read as follows:\nroot@farmstack:~#\n5. \nIt is good practice to create a new user account that will have all the necessary privileges so that \nwe don’t use the root account for our web hosting. Let’s create an account called farmuser:\nadduser farmuser\n",
        "img": [],
        "translation": "在DigitalOcean上部署FastAPI（或任何Linux服务器！）\n\nDigitalOcean最出色的地方之一是它的优秀社区和无尽的精心编写的文章，涵盖任何您想要实现的服务或设置，因此如果您进入了部署、数据库设置等领域，则DigitalOcean是一个很好的起点。请注意，DigitalOcean及其竞争对手（例如Linode）完全能够托管我们的完整全栈设置-我们也可以在服务器上安装MongoDB，添加Node.js和Next或React前端，并通过Nginx对所有内容进行编排， 一个强大而快速的服务器。然而，在此示例中，我们仅想提供FastAPI实例并展示不同类型的部署。按照以下步骤：\n\n1. 创建DigitalOcean帐户！转到DigitalOcean注册页面 https://\ncloud.digitalocean.com/registrations/new 并填写您的数据。如果您愿意，可以使用GitHub或Google进行注册，如果您有推荐代码，也可以使用推荐代码，以便您可以在规定的时间内尝试该服务。一旦您提交了数据（并且一旦您有一些信用可以支配-无论是来自推荐计划还是在连接信用卡之后），您将能够创建您的第一个虚拟机。\n\n2. 创建Droplet。我使用的是Ubuntu 22.04 x64 Ubuntu发行版，计划是Basic（最便宜的），CPU选项是$4 /月，512 MB / 1 CPU（您必须单击左箭头才能找到此计划！）。由于我在欧洲，我选择了法兰克福数据中心区域。最后，为了简化事情，我选择了密码验证，因此我输入了一个根密码（我不会在这里披露！）。 我给主机名命名-farmstack。尽管我们将使用IP地址通过SSH访问此全新的机器，但拥有一个用户友好的机器名称很有用。\n\n请给DigitalOcean一些时间来准备您的Droplet。大约30秒后，您将能够单击左侧菜单下的Droplets，并进入显示有关Droplet的信息的页面。现在，您拥有了基于Ubuntu的服务器，可以控制它！\n\n3. 为了验证您确实能够作为根登录到您的全新机器上，请单击Droplet的IP地址以将其复制，然后在Windows上打开Cmder（或您一直在使用的任何shell）或如果您是在Linux或macOS上，则打开bash / shell，然后尝试访问Droplet：\n\nssh root@<your_IP_address_that_you_just_copied>\n\n4. Cmder会友善地告诉您无法确认主机的真实性，这在此阶段是正常的，并问您是否要继续连接。键入是；您将被问候以下Shell：\n\nroot@farmstack:~#\n\n5. 为了遵循良好的实践，创建一个具有所有必要特权的新用户帐户，以便我们不使用根帐户进行Web托管。让我们创建一个名为farmuser的帐户：\n\nadduser farmuser"
    },
    "4": {
        "text": "Caching with Redis and Deployment on Ubuntu (DigitalOcean) and Netlify\n282\n6. \nYou will be asked to provide a password (twice), a name, and some other information, such \nas a room number (!). It is important to remember the password! This newly created user will \nneed to be able to perform various administrative tasks, so we should grant them adequate \nprivileges. In the same SSH session, type the following:\nusermod -aG sudo farmuser\nAfter this, when we log in as farmuser, we will be able to just type sudo before performing \nactions that require superuser powers.\nWe will make use of the UFW firewall to make sure that only certain types of connections to \nour server are permitted. There are different options when it comes to DigitalOcean’s firewalls, \nbut this should be more than enough and easy to set up on different machines. Things may get \ntricky, though – we need to make sure that when we leave our SSH root shell, we will be able \nto get back in with our farmuser account!\n7. \nTo be sure that OpenSSH is allowed to access the machine, type the following:\nufw allow OpenSSH\n8. \nYou should see a message saying rules updated. Now, let’s enable ufw and check its status:\nufw enable\nufw status\nThe preceding commands should warn you that they may disrupt existing SSH connections; \nconfirm the first one anyway. The second should just inform you that the service is active. \n9. \nGreat. Now, Keep the SSH session alive and open a new terminal so that we can test our \nconnection with our regular yet highly privileged farmuser:\nssh farmuser@<your_IP_address_that_you_just_copied>\nYou should be greeted with a prompt; that is, farmuser@farmstack:~$. That’s great – \nnow, we can proceed with this (regular) user and use sudo when we need to do tricky stuff!\nIt is time to update our Ubuntu packages and add some more. Logged in as farmuser (or \nwhatever your regular, non-root username was), issue the following command:\nsudo apt update\nsudo apt install python3-venv nginx curl\nsudo will prompt you for a password – your regular farmuser password – so kindly provide \nit. Apart from Python 3, we are installing Nginx, our powerful web server and reverse proxy \nsolution, and curl (to test our API service locally).\n",
        "img": [],
        "translation": "使用Redis缓存并在Ubuntu（DigitalOcean）和Netlify上部署\n\n6. \n要求提供密码（两次）、名称和其他信息，例如房间号码(!)。记住该密码非常重要！这个新创建的用户需要具备各种管理任务的能力，因此我们应该授予他们足够的特权。在同一SSH会话中，输入以下内容:\nusermod -aG sudo farmuser\n之后，当我们以farmuser身份登录时，只需在执行需要超级用户权限的操作前键入sudo即可。\n\n我们将利用UFW防火墙，以确保只有特定类型的连接被允许连接到我们的服务器。当涉及到DigitalOcean的防火墙时，有不同的选项，但这应该足够易于在不同的机器上设置。尽管如此，事情可能会变得有些棘手 - 我们需要确保当我们离开我们的SSH根shell时，我们将能够使用我们的farmuser帐户重新登录！\n\n7. \n为确保OpenSSH被允许访问该机器，输入以下命令:\nufw allow OpenSSH\n\n8. \n您应该会看到一条消息，表示规则已更新。现在，让我们启用ufw并检查其状态:\nufw enable\nufw status\n前述命令应该会警告您可能会干扰现有的SSH连接；无论如何，确认第一个命令即可。第二个命令应该只会通知您该服务正在运行。\n\n9. \n太好了。现在，保持SSH会话保持活动状态，并打开一个新的终端，以便我们可以测试我们的常规但高度特权的farmuser的连接:\nssh farmuser@<your_IP_address_that_you_just_copied>\n您应该看到一个提示符，即farmuser@farmstack:~$。这很好 - 现在，我们可以继续使用此（常规）用户，并在需要进行复杂操作时使用sudo！\n\n现在是时候更新我们的Ubuntu软件包并添加一些新的软件包了。以farmuser（或其他常规的非root用户名）身份登录，执行以下命令:\nsudo apt update\nsudo apt install python3-venv nginx curl\nsudo将提示您输入密码 - 您的常规farmuser密码 - 请提供。除了Python 3之外，我们还安装了Nginx（我们强大的Web服务器和反向代理解决方案）和curl（用于在本地测试我们的API服务）。"
    },
    "5": {
        "text": "Deploying FastAPI on DigitalOcean (or really any Linux server!)\n283\nNow, we are entering the second, project-related phase of our deployment. It is time to create a virtual \nenvironment, just like we did numerous times during the development phase. This is a bare-bones \nserver, so we have to do everything manually. There is no helpful guiding hand like there was with \nHeroku or Vercel. Follow these steps:\n1. \nLet’s create a directory called apiserver in our home folder and cd into it (you can always \nsee where you are currently located with PWD!):\nmkdir ~/apiserver\ncd ~/apiserver\n2. \nNow, let’s create a Python 3 environment:\npython3 -m venv venv \n3. \nAfter the setup has finished, go ahead and activate this environment with the following command:\nsource venv/bin/activate\nYou should see venv prepending the command prompt.\n4. \nIt is time to grab the address of the GitHub repository that you created for the backend and \nchange the directory to our /apiserver. Now, clone the GitHub repo inside to get all the code:\ngit clone <your repo address>\nThis will create a folder with the same name as the repository – in my case, it is a bit cumbersome: \nFARM-chapter9-backend. Cloning the code from the repo will not copy the .env file \nwith the necessary keys for MongoDB and Sendgrid (and Cloudinary in the previous app). \n5. \nAlthough we could set the environment variables manually through the shell, we are just going \nto blatantly copy them using the secure copy scp command. Make sure you’re in your local \ncomputer’s /backend folder and take note of the remote folder. Then, issue the following \ncommand:\nscp .env farmuser@207.154.254.114:~/apiserver/FARM-\nchapter9-backend\n6. \nNow try out the ls command to make sure that the folder with the code is indeed there, but \nkeep in mind that the .env file will not be shown! You will have to use something such as \nnano .env to verify that the file is indeed there and that it contains the necessary information. \nIf you don’t want to mess with scp, you can just create and type in the .env file using nano \n– the powerful command-line text editor provided by Linux systems.\n7. \nOnce the code is in the Ubuntu droplet, cd into the directory and install all the dependencies \nwith the following command:\npip install -r requirements.txt\n",
        "img": [],
        "translation": "部署FastAPI到DigitalOcean（或任何Linux服务器！）\n\n现在，我们进入第二个与项目有关的阶段，即部署阶段。现在是时候创建虚拟环境了，就像我们在开发阶段做的那样。这是一个基础的服务器，所以我们必须手动完成所有步骤。没有像Heroku或Vercel那样提供有帮助的指导。请按照以下步骤操作：\n\n1.让我们在我们的主文件夹中创建一个名为apiserver的目录并进入它（您始终可以通过PWD查看当前位置！）：\n\nmkdir〜/ apiserver\ncd〜/ apiserver\n\n2.现在，让我们创建一个Python 3环境：\n\npython3 -m venv venv\n\n3.安装完成后，使用以下命令激活此环境：\n\nsource venv / bin / activate\n\n您应该在命令提示符前看到venv。\n\n4.现在是时候获取您为后端创建的GitHub仓库的地址并将目录更改为/apiserver。接下来，克隆GitHub仓库内的所有代码：\n\ngit clone <您的repo地址>\n\n这将创建与存储库名称相同的文件夹-在我的情况下，它有点繁琐：FARM-chapter9-backend。从存储库克隆代码不会同时复制具有MongoDB和Sendgrid（以前的应用程序中的Cloudinary）所需密钥的.env文件。\n\n5.尽管我们可以通过shell手动设置环境变量，但我们将使用安全复制scp命令来进行明显的复制。确保您位于本地计算机的/ backend文件夹中，并注意远程文件夹。然后，发出以下命令：\n\nscp .env farmuser@207.154.254.114：〜/ apiserver / FARM-\nchapter9-backend\n\n6.现在尝试ls命令，以确保代码文件夹确实存在，但请记住，.env文件不会显示！您必须使用诸如nano .env之类的东西来验证文件确实存在并且包含所需信息。如果您不想用scp搞砸，可以使用nano（由Linux系统提供的强大的命令行文本编辑器）创建并输入.env文件。\n\n7.一旦代码在Ubuntu droplet中，就进入目录并使用以下命令安装所有依赖项：\n\npip install -r requirements.txt"
    },
    "6": {
        "text": "Caching with Redis and Deployment on Ubuntu (DigitalOcean) and Netlify\n284\nImportant Note \nAfter committing the code for the backend, you should update the requirements.txt \nfile by typing pip freeze > requirements.txt, while being within the activated \nvirtual environment on your local machine. This file should then be committed to GitHub – it \nwill be our magic ingredient for recreating the same virtual environment on other machines, \nincluding our droplet!\n8. \nOnce the dependencies have been installed, we can test our application with the standard \nUvicorn command:\nuvicorn main:app –reload\nThe prompt should inform you that Uvicorn is running on http://127.0.0.1:8000 \nbut that we cannot access it yet from the outside. \n9. \nStop the server with Ctrl + C. To be able to test that the API is working, we have to disable our \nUFW firewall. To do that, you have to sudo your way through it:\nsudo ufw disable\nNotice\nThis is a dangerous practice – a bit like leaving your front door open.\nNow, if you try to rerun the Uvicorn server, you should be able to access your API with a REST client \nor a browser at the IP address of your droplet, on port 8000! So far, we are only trying out what we \nhave been doing throughout this book on DigitalOcean. Now, it is time to introduce Gunicorn.\nImportant Note\nGunicorn is a mature and battle-tested WSGI Python server for UNIX. It is often used in \nconjunction with Uvicorn since it is highly configurable and able to handle Uvicorn workers \nefficiently. The Uvicorn documentation itself recommends a setup that includes Gunicorn and \nNginx and that is exactly what we are going to do! Gunicorn is an interesting and powerful project \nin its own right and its documentation is is a useful read (https://gunicorn.org/).\nLet’s build our deployment now. Follow these steps:\n1. \nInstall gunicorn with a simple call to pip:\npip install gunicorn\n",
        "img": [],
        "translation": "使用Redis缓存和在Ubuntu（DigitalOcean）和Netlify上部署\n\n重要提示\n在提交后端代码之后，您应该更新requirements.txt文件，方法是在本地计算机上已激活的虚拟环境中键入pip freeze> requirements.txt。然后将此文件提交到GitHub - 它将是在其他计算机上重建相同虚拟环境的必备材料，包括我们的droplet！\n\n8. \n安装完依赖项后，我们可以使用标准的Uvicorn命令测试我们的应用程序：\nuvicorn main:app -reload\n提示应该告诉您Uvicorn正在运行http：// 127.0.0.1：8000，但我们尚无法从外部访问它。\n\n9. \n使用Ctrl + C停止服务器。要能够测试API是否起作用，我们必须禁用UFW防火墙。为此，您必须sudo通过它：\nsudo ufw disable\n注意\n这是一种危险的做法，有点像把前门开着。\n\n现在，如果您尝试重新运行Uvicorn服务器，您应该能够使用REST客户端或浏览器在droplet的IP地址上，端口为8000，访问您的API！到目前为止，我们一直在DigitalOcean上尝试我们在本书中所做的事情。现在，是时候介绍Gunicorn了。\n\n重要提示\nGunicorn是一款成熟且经过战斗考验的Unix WSGI Python服务器。它通常与Uvicorn一起使用，因为它高度可配置并能够高效处理Uvicorn工作程序。 Uvicorn文档本身建议包含Gunicorn和Nginx的设置，这正是我们要做的！ Gunicorn本身是一个有趣且强大的项目，它的文档是有用的阅读（https://gunicorn.org/）。\n现在让我们开始构建我们的部署。按照以下步骤操作：\n\n1. \n使用pip简单调用安装gunicorn：\npip install gunicorn"
    },
    "7": {
        "text": "Deploying FastAPI on DigitalOcean (or really any Linux server!)\n285\n2. \nAfter installing gunicorn, we can start our API server with the following command (while \nstaying in the source code directory!):\ngunicorn --bind 0.0.0.0:8000 main:app -w 4 -k uvicorn.\nworkers.UvicornWorker\nThe preceding command starts a gunicorn server with four uvicorn workers. Gunicorn provides \nalso load balancing functionality for our Uvicorn servers – an async request that might be taking \na bit too long won’t hog up the system. Now, we can test our app on port 8000. \nNow, we are going to use Linux’s powerful systemd service and socket files to make the server \nstart and stop programmatically.\nImportant Note\nsystemd is a process and system manager for Linux systems. If you wish to get to know its \ncapabilities and functionalities, I can recommend (another) very useful article from the \nDigitalOcean knowledge database: https://www.digitalocean.com/community/\ntutorials/systemd-essentials-working-with-services-units-and-\nthe-journal. Again, in these pages, we will only explain the commands that we will be \nusing – starting, stopping, and enabling and disabling services, servers, and so on.\n3. \nWe are going to have to use a bit of nano, the command-line text editor of choice for the \nmajority of Linux distributions. Stop the gunicorn server with Crtl + C and deactivate the \nvirtual environment with a simple deactivate. The prepended venv should be gone. \n4. \nNow, let’s create a gunicorn socket. Sockets are simply communication points on the same or \ndifferent computers that enable systems to exchange data. When we create a Gunicorn socket, \nit is just a way of telling the system that the created socket can be used to access data that the \nserver will provide:\nsudo nano /etc/systemd/system/gunicorn.socket\nThe file’s content should be as follows (fully adapted from the aforementioned ASGI Django guide):\n[Unit]\nDescription=gunicorn socket\n[Socket]\nListenStream=/run/gunicorn.sock\n[Install]\nWantedBy=sockets.target\n",
        "img": [],
        "translation": "在DigitalOcean（或任何Linux服务器上）部署FastAPI！\n\n在安装gunicorn之后，我们可以使用以下命令启动API服务器（保持在源代码目录中！）：\ngunicorn --bind 0.0.0.0:8000 main:app -w 4 -k uvicorn.workers.UvicornWorker\n上述命令启动带有四个uvicorn工作进程的gunicorn服务器。Gunicorn还为我们的Uvicorn服务器提供负载均衡功能-异步请求可能会花费一些时间，但不会占用系统资源。现在，我们可以在端口8000上测试我们的应用程序。\n\n现在，我们要使用Linux强大的systemd服务和socket文件使服务器能够在程序中启动和停止。\n\n重要提示\nsystemd是Linux系统的进程和系统管理器。如果您想了解其功能和功能，我可以推荐（另一篇）非常有用的DigitalOcean知识库文章：https://www.digitalocean.com/community/tutorials/systemd-essentials-working-with-services-units-and-the-journal。在这些页面中，我们只会解释我们将使用的命令-启动、停止、启用和禁用服务、服务器等。\n\n我们将不得不使用一些nano，这是大多数Linux发行版的命令行文本编辑器。使用Crtl + C停止gunicorn服务器，并使用简单的deactivate取消激活虚拟环境。前置的venv应该消失了。\n\n现在，让我们创建一个gunicorn socket。套接字是简单地在同一台或不同计算机上的通信点，使系统能够交换数据。当我们创建Gunicorn套接字时，这只是告诉系统创建的套接字可用于访问服务器将提供的数据：\n\nsudo nano /etc/systemd/system/gunicorn.socket\n文件的内容应如下（完全改编自前面提到的ASGI Django指南）：\n[Unit]\nDescription=gunicorn socket\n[Socket]\nListenStream=/run/gunicorn.sock\n[Install]\nWantedBy=sockets.target"
    },
    "8": {
        "text": "Caching with Redis and Deployment on Ubuntu (DigitalOcean) and Netlify\n286\n5. \nTo leave nano, just type Ctrl + X and type yes when asked to confirm. The filename should \nremain the same as what we gave it initially.\n6. \nNow, we are going to create the gunicorn.service file. Again, fire up nano with the \nfollowing command:\nsudo nano /etc/systemd/system/gunicorn.service\n7. \nBegin typing the following:\n[Unit]\nDescription=gunicorn daemon\nRequires=gunicorn.socket\nAfter=network.target\n[Service]\nUser=farmuser\nGroup=www-data\nWorkingDirectory=/home/farmuser/apiserver/FARM-chapter9-\nbackend\nExecStart=/home/farmuser/apiserver/venv/bin/gunicorn \\\n          --access-logfile - \\\n          -k uvicorn.workers.UvicornWorker \\\n          --workers 3 \\\n          --bind unix:/run/gunicorn.sock \\\n          main:app\n[Install]\nWantedBy=multi-user.target\nI have highlighted the essential parts and paths that you should triple-check before saving. It \nis important to emphasize that the working directory is the directory hosting our code, while \nexecstart is referring to the virtualenv directory. In our case, they are side by side \ninside the apiserver folder! This should be enough for systemd. \n8. \nSave the file and let’s try it out. Start and enable the newly created gunicorn socket with the \nfollowing commands: \nsudo systemctl start gunicorn.socket\nsudo systemctl enable gunicorn.socket\n",
        "img": [],
        "translation": "使用Redis进行缓存以及在Ubuntu（DigitalOcean）和Netlify上部署\n\n5. 要退出nano，请键入Ctrl + X，并在要求确认时键入yes。文件名应该与我们最初给出的相同。\n\n6. 现在，我们将创建gunicorn.service文件。再次使用以下命令启动nano：\nsudo nano /etc/systemd/system/gunicorn.service\n\n7. 开始输入以下内容：\n[Unit]\nDescription = gunicorn的守护进程\nRequires = gunicorn.socket\nAfter = network.target\n\n[Service]\nUser = farmuser\nGroup = www-data\nWorkingDirectory = /home/farmuser/apiserver/FARM-chapter9- backend\nExecStart = /home/farmuser/apiserver/venv/bin/gunicorn \\\n          --access-logfile - \\\n          -k uvicorn工作者.UvicornWorker \\\n          --workers 3 \\\n          --bind unix：/run/gunicorn.sock \\\n          main：app\n\n[Install]\nWantedBy = multi-user.target\n\n我已经突出显示了您应该三次检查的重要部分和路径，然后保存。强调工作目录是托管我们的代码的目录，而execstart是指虚拟环境目录。在我们的例子中，它们并排放置在apiserver文件夹中！这对于systemd应该足够了。\n\n8. 保存文件，让我们来试试吧。使用以下命令启动和启用新创建的gunicorn套接字：\nsudo systemctl start gunicorn.socket\nsudo systemctl enable gunicorn.socket"
    },
    "9": {
        "text": "Deploying FastAPI on DigitalOcean (or really any Linux server!)\n287\n9. \nIf everything went right, there shouldn’t be any errors. You should, however, check the status \nof the socket:\nsudo systemctl status gunicorn.socket\n10. You should also check for the existence of the gunicorn.sock file:\nfile /run/gunicorn.sock\n11. Now, activate the socket:\nsudo systemctl status gunicorn\n12. With that, we should be able to (finally!) test our API with curl:\ncurl --unix-socket /run/gunicorn.sock localhost/cars/all\nYou should get a bunch of cars flooding the terminal since we’ve hit our cars endpoint!\nWe’re nearly there, hang on! Now, we will use Nginx to route the incoming traffic. Follow these steps:\nImportant Note\nNginx is an extremely powerful, reliable, and fast web server, load balancer, and proxy server. At \nits most basic, Nginx reads its configuration and, based on this information, decides what to do \nwith each request that it encounters – it can simultaneously handle multiple websites, multiple \nprocesses, and the most diverse configurations that you throw at it. You may have a bunch of \nstatic files, images, and documents in one location on the server, a Node.js API managed by \nPM2, a Django or Flask website, and maybe a FastAPI instance all at once. With the proper \nconfiguration, Nginx will be able to effortlessly take care of this mess and always serve the right \nresource to the right client. At least some basic knowledge of how Nginx operates can be a \nvery useful tool to have under your belt, and the nginx.org website is a great place to start.\n13. Nginx operates in server blocks, so let’s create one for our apiserver:\nserver {\n    listen 80;\n    server_name <your droplet's IP address>\n    location = /favicon.ico { access_log off; log_not_\nfound off; }\n    \n    location / {\n        include proxy_params;\n        proxy_pass http://unix:/run/gunicorn.sock;\n",
        "img": [],
        "translation": "将FastAPI部署到DigitalOcean（或任何Linux服务器！）\n\n如果一切正常，就不应该有任何错误。但是，您应该检查套接字的状态：\nsudo systemctl status gunicorn.socket\n\n您也应该检查gunicorn.sock文件的存在：\nfile /run/gunicorn.sock\n\n现在，激活套接字：\nsudo systemctl status gunicorn\n\n这样，我们应该能够（终于！）用curl测试我们的API：\ncurl --unix-socket /run/gunicorn.sock localhost/cars/all\n\n由于我们已经访问了汽车端点，您应该会在终端下看到一堆汽车！\n\n我们临近成功了！现在，我们将使用Nginx来路由传入的流量。请按照以下步骤操作：\n\n重要提示\n\nNginx是一个非常强大、可靠且快速的Web服务器、负载均衡器和代理服务器。最基本的，Nginx读取其配置，并根据这些信息决定如何处理遇到的每个请求-它可以同时处理多个网站、多个进程和你向它扔出的最多样化的配置。您可能会在服务器上有一堆静态文件、图像和文档、由PM2管理的Node.js API、Django或Flask网站，以及可能同时存在的FastAPI实例。通过适当的配置，Nginx将能够轻松地处理这个混乱，并始终向正确的客户端提供正确的资源。至少了解Nginx如何操作的一些基本知识可以成为您手头非常有用的工具，而nginx.org网站是一个很好的起点。\n\n13. Nginx在服务器块中操作，因此让我们为我们的apiserver创建一个：\nserver {\n    listen 80;\n    server_name <your droplet's IP address>\n    location = /favicon.ico { access_log off; log_not_\nfound off; }\n    \n    location / {\n        include proxy_params;\n        proxy_pass http://unix:/run/gunicorn.sock;"
    },
    "10": {
        "text": "Caching with Redis and Deployment on Ubuntu (DigitalOcean) and Netlify\n288\n    }\n}\nOnce you get used to Nginx’s server block syntax, you will be serving websites (or processes, \nto be precise) in no time. In the preceding code, we instructed Nginx to listen on the default \nport (80) for our machine (IP address) and to redirect all traffic to our Unix Gunicorn socket!\n14. Now, enable the file by copying it to the sites-enabled folder of Nginx, as follows:\nsudo ln -s /etc/nginx/sites-available/myproject /etc/\nnginx/sites-enabled\nThere is a very handy command that allows us to check if the Nginx configuration is valid:\nsudo nginx -t\n15. If Nginx is not complaining, we can restart it by typing the following command; then, we \nshould be good to go:\nsudo systemctl restart nginx\n16. The last thing we must do is set up the ufw firewall again, allow Nginx to pass through, and \nclose port 8000 by removing the rule that allowed it:\nsudo ufw delete allow 8000\nsudo ufw allow 'Nginx Full'\nCongratulations! You are now serving your API through a robust setup that consists of Uvicorn, \nGunicorn, and Nginx. With this setup, we have a plethora of options. You could serve static files (images, \nstylesheets, or documents) blazingly fast through Nginx. You could also set up a Next.js project and \nmanage it through PM2 (https://pm2.keymetrics.io/), a powerful Node.js process manager. \nWe will stop here, although there are many – not so complicated – steps to go through before we have \na production-ready system.\nAdding caching with Redis\nRedis is among the top technologies when it comes to NoSQL data storage options, and it is very \ndifferent from MongoDB. Redis is an in-memory data structure store, and it can be used as a database, \ncache, message broker, and also for streaming. Redis provides simple data structures – hashes, lists, \nstrings, sets, and more –and enables scripting with the Lua language. While it can be used as a primary \ndata store, it is often used for caching or running analytics and similar tasks. Since it is built to be \nincredibly fast (much faster than MongoDB, to be clear), it is ideal for caching database or data store \nqueries, results of complex computations, API calls, and managing the session state. MongoDB, on \nthe other hand, while being fast and flexible, if it scales sufficiently, could slow down a bit. Bearing \nin mind that we often (as is the case in this chapter) host MongoDB on one server (Atlas Cloud) and \n",
        "img": [],
        "translation": "Redis缓存和在Ubuntu（DigitalOcean）和Netlify上的部署\n\n当你习惯了Nginx的服务器块语法，你将很快为网站（或进程）提供服务。在上面的代码中，我们指示Nginx在我们机器（IP地址）的默认端口（80）上监听，并将所有流量重定向到我们的Unix Gunicorn套接字！\n\n14.现在，通过以下方式将文件复制到Nginx的sites-enabled文件夹中以启用它：\nsudo ln -s /etc/nginx/sites-available/myproject /etc/\nnginx/sites-enabled\n有一种非常方便的命令可以让我们检查Nginx配置是否有效：\nsudo nginx -t\n15.如果Nginx没有抱怨，我们可以通过输入以下命令来重新启动它，然后我们就可以开始工作了：\nsudo systemctl restart nginx\n16.我们要做的最后一件事是再次设置ufw防火墙，允许Nginx通过，并通过删除允许其通过的规则来关闭端口8000：\nsudo ufw delete allow 8000\nsudo ufw allow 'Nginx Full'\n恭喜！现在您可以通过由Uvicorn、Gunicorn和Nginx组成的强大系统提供API服务。通过这个设置，我们有大量的选项。您可以通过Nginx来快速服务静态文件（图片、样式表或文档）。你也可以设置一个Next.js项目，并通过PM2（https://pm2.keymetrics.io/）管理它，这是一个强大的Node.js进程管理器。我们到此为止，尽管在我们拥有一个生产就绪的系统之前，还有许多不太复杂的步骤要经历。\n\n使用Redis添加缓存\n\nRedis在NoSQL数据存储选项中排名前列，与MongoDB非常不同。Redis是一个内存数据结构存储，它可以用作数据库、缓存、消息代理，也可以用于流媒体。Redis提供简单的数据结构——哈希、列表、字符串、集合等等，并支持Lua语言脚本。虽然它可以用作主要的数据存储，但通常用于缓存或运行分析等任务。由于它被构建为非常快（比MongoDB快得多，要明确），因此它非常适合缓存数据库或数据存储查询、复杂计算的结果、API调用以及管理会话状态。另一方面，MongoDB虽然快速且灵活，但如果它足够大规模，它可能会变慢。请记住，我们经常（如本章）在一个服务器（Atlas Cloud）上托管MongoDB，并使用另一个服务器来提供API服务。因此，我们在这里添加Redis缓存来提高性能。下面是Redis配置的步骤：\n\n17.在您的服务器上安装Redis：\nsudo apt update\nsudo apt install redis-server\n\n18.验证Redis是否运行：\nredis-cli ping\n如果响应是pong，则Redis正在运行。\n\n19.打开项目的.env文件，添加以下行：\nREDIS_HOST=localhost # Redis服务器\nREDIS_PORT=6379 # Redis端口\nREDIS_DB=0 # Redis数据库\n\n20.打开项目的Dockerfile文件，并追加以下命令：\nRUN pip install redis\n这将安装Redis的Python客户端。\n\n21.重新启动容器：\ndocker-compose down\ndocker-compose up -d\n\n22.打开项目的FastAPI应用，并引入redis包：\nimport redis\n\n23.更新FastAPI应用程序的根路由以添加缓存。在此示例中，我们将存储名为my_key和值为my_value的内容：\nredis_store = redis.StrictRedis(\n    host=settings.REDIS_HOST, port=settings.REDIS_PORT, db=settings.REDIS_DB\n)\n\n@app.get(\"/\")\nasync def read_root():\n    redis_store.set(\"my_key\", \"my_value\")\n    return {\"Hello\": \"World\", \"redis_value\": redis_store.get(\"my_key\")}\n\n24.您应该能够看到类似以下输出的响应：\n{\"Hello\": \"World\", \"redis_value\": \"my_value\"}\n\n恭喜！现在您已经学会了如何将Redis缓存集成到我们的项目中。要了解有关Redis的更多信息，请访问https://redis.io/documentation。"
    },
    "11": {
        "text": "Adding caching with Redis\n289\nour FastAPI code on another one (DigitalOcean or Heroku), latency also might affect the response \ntimes. Imagine if we wanted to perform a complex aggregation instead of the simple ones that we have \ncreated in this chapter. By throwing in some data science, such as algorithms with interpolations or \nmachine learning algorithms, we could be in trouble should our website become popular (and it will!). \nCaching to the rescue! What is caching? It is a really simple concept that has been around for decades \n– the basic idea is to store some frequently requested data (from a Mongo database, in our case) in \nsome type of temporary storage for some time until it expires. The first user requesting said resource \n(a list of cars) will have to wait for the whole query to complete and will get the results. These results \nwill then automatically be added to this temporary storage (in our case, Redis, the Usain Bolt of \ndatabases) and served to all subsequent requests for the same data. By the same data, we usually imply \nthe same endpoint. This process persists until the data stored in Redis (or any other caching solution \nthat you may use) expires – if valid data is not found in the cache, the real database call is made again \nand the process repeats. \nThe expiry time is of crucial importance here – in our case, if we are working with a car-selling company, \nwe can be generous with caching and extend the expiry period to 10 minutes or even more. In more \ndynamic applications, such as forums or similar conversational environments, a much lower expiry \ntime would be mandatory to preserve functionality.\nInstalling Redis on Linux is quite simple, while on Windows it is not officially supported. You could \nfollow the official guide for installing Redis for development purposes on Windows (https://\nredis.io/docs/getting-started/installation/install-redis-on-windows/) \nbut that is beyond the scope of our application. We will, however, install Redis on our DigitalOcean \nLinux box and add caching to our FastAPI application!\nConnect to your DigitalOcean box (or to your Linux system of choice – if you are developing on \nLinux or Mac, you should install it there as well) by following the steps from this chapter, while using \nSSH from a terminal:\n1. \nNow, install Redis by typing the following command:\nsudo apt install redis-server\nImportant Note \nIn a production environment, you should secure your Redis server with a disgustingly long \npassword. Since Redis is fast, an attacker could potentially run hundreds of thousands of \npasswords in mere seconds against it during a brute-force attack. You should also disable or \nrename some potentially dangerous Redis commands. In these pages, we are only showing how \nto add a bare-bones, not-secured Redis instance to our setup.\n",
        "img": [],
        "translation": "使用Redis添加缓存\n\n如果我们将FastAPI代码部署到另一个平台（比如DigitalOcean或Heroku），响应时间可能会受到延迟的影响。想象一下，如果我们想执行复杂的聚合操作，而不是在本章中创建的简单操作，那么缓存就派上用场了！什么是缓存？这是一个非常简单的概念，已经存在了几十年，基本思想是将一些经常被请求的数据（从Mongo数据库中，例如）存储在某种类型的临时存储中，直到失效。第一个请求该资源（如汽车列表）的用户将不得不等待整个查询完成并获得结果。这些结果将自动添加到此临时存储（在我们的情况下，即Redis，数据库中的Usain Bolt）中，并提供给所有后续请求相同数据的用户。通常，我们认为相同的数据指的是相同的终端点。此过程持续到Redis中存储的数据（或者您可能使用的任何其他缓存解决方案）过期-如果在缓存中未找到有效数据，则再次进行真实数据库调用并重复此过程。 \n\n过期时间在这里非常重要-在我们的情况下，如果我们正在与一家汽车销售公司合作，我们可以慷慨地使用缓存并将过期时间延长到10分钟或更长时间。在更动态的应用程序中，如论坛或类似的对话环境，更短的到期时间将是必需的，以维护功能。\n\n在Linux上安装Redis非常简单，而在Windows上它并没有官方支持。您可以按照官方指南在Windows上安装Redis进行开发（https：//redis.io/docs/getting-started/installation/install-redis-on-windows/），但这超出了我们应用程序的范围。然而，我们将在DigitalOcean Linux盒子上安装Redis，并将缓存添加到我们的FastAPI应用程序中！\n\n请按照本章中的步骤连接到DigitalOcean盒子（或您选择的Linux系统-如果您正在Linux或Mac上开发，也应在那里安装Redis）：\n\n1.\n\n然后，通过键入以下命令安装Redis：\nsudo apt install redis-server\n重要提示\n\n在生产环境中，您应该使用一个非常长的密码来保护您的Redis服务器。由于Redis速度快，攻击者可能在几秒钟内对其运行数十万个密码进行暴力攻击。您还应该禁用或重命名一些潜在危险的Redis命令。在这些页面中，我们仅显示如何向我们的设置中添加一个裸骨而不安全的Redis实例。"
    },
    "12": {
        "text": "Caching with Redis and Deployment on Ubuntu (DigitalOcean) and Netlify\n290\n2. \nNow, we should restart the Redis service. Although it should happen automatically, let’s make \nsure by typing the following command:\nsudo systemctl restart redis.service\n3. \nTest it by typing the following command to see if it is working:\nsudo systemctl status redis\nThe Terminal will send an ample response, but what you are looking for is the green word \nActive (running). It should also be started automatically with every reboot – so we get that \ngoing for us, which is nice.\n4. \nThe traditional way to test that Redis is responding is to start the client:\nredis-cli\nThen, in the Redis shell, type ping.\nRedis should respond with pong and the prompt should say 127.0.0.1:6379. This means that Redis \nis running on localhost (the Linux server) on port 6379. Remember this address, or better, write it \ndown somewhere (I know, I know). We are going to need it for our FastAPI server.\nThere are many ways to make Redis talk to Python, but here, we will opt for a simple module aptly \nnamed Fastapi-cache (https://github.com/long2ice/fastapi-cache). Now, we will \nhave to edit our backend code in the /backend folder. When we’re done, we will push the changes \nto GitHub and repeat the deployment procedure. Or, if you just want to quickly try out the caching, \nyou could edit the files on DigitalOcean directly by navigating to the directory and using nano.\nAnyway, activate the virtual environment of your choice and install the package and aioredis (the \nasync Python Redis driver):\npip install fastapi-cache2 aioredis\nNow, our FastAPI project structure dictates which files need to be updated. We need to update our \nmain.py file and add the following imports:\nimport aioredis\nfrom fastapi_cache import FastAPICache\nfrom fastapi_cache.backends.redis import RedisBackend\nThen, we need to update our startup event handler:\n@app.on_event(\"startup\")\nasync def startup_db_client():\n    app.mongodb_client = AsyncIOMotorClient(DB_URL)\n",
        "img": [],
        "translation": "使用Redis缓存和部署在Ubuntu（DigitalOcean）和Netlify上\n\n2. 现在，我们应该重新启动Redis服务。虽然它应该自动发生，但让我们通过输入以下命令来确保：\nsudo systemctl restart redis.service\n\n3. 通过输入以下命令进行测试，以查看它是否工作：\nsudo systemctl status redis\n终端将发送大量响应，但您要查找的是绿色单词“Active（运行中）”。它还应自动启动每次重启 - 所以我们为此努力赚钱。\n\n4. 测试Redis是否响应的传统方法是启动客户端：\nredis-cli\n然后，在Redis shell中，输入ping。\nRedis应该响应pong，并且提示应该说127.0.0.1：6379。这意味着Redis正在本地主机（Linux服务器）的6379端口上运行。记住这个地址，或更好的是，将其写在某个地方（我知道，我知道）。我们将需要它用于我们的FastAPI服务器。\n\n有许多方法使Redis与Python交互，但在这里，我们将选择一个名为Fastapi-cache的简单模块（https://github.com/long2ice/fastapi-cache）。现在，我们需要编辑/backend文件夹中的后端代码。完成后，我们将推送更改到GitHub并重复部署过程。或者，如果您只想快速尝试缓存，则可以直接导航到目录并使用nano在DigitalOcean上直接编辑文件。\n\n无论如何，请激活您选择的虚拟环境并安装软件包和aioredis（异步Python Redis驱动程序）：\npip install fastapi-cache2 aioredis\n现在，我们的FastAPI项目结构规定需要更新哪些文件。我们需要更新我们的main.py文件并添加以下导入：\nimport aioredis\nfrom fastapi_cache import FastAPICache\nfrom fastapi_cache.backends.redis import RedisBackend\n然后，我们需要更新我们的启动事件处理程序：\n@app.on_event（“startup”）\nasync def startup_db_client（）：\n    app.mongodb_client = AsyncIOMotorClient（DB_URL）"
    },
    "13": {
        "text": "Adding caching with Redis\n291\n    app.mongodb = app.mongodb_client[DB_NAME]\n    redis = aioredis.from_url(\n        \"redis://localhost:6379\", encoding=\"utf8\", decode_\n            responses=True\n    )\n    FastAPICache.init(RedisBackend(redis), prefix=\"fastapi-\n        cache\")\nThe code makes sense – we’re getting a Redis client, just like we did with Mongo, and we are passing \nthe URL and a couple of (suggested) settings. Finally, we initialized the FastAPICache. Now, we need \nto add the caching decorator to our endpoints, which are located in the /routers/cars.py file. \nWe will add one import:\nfrom fastapi_cache.decorator import cache\nNow, we can decorate the routes that we wish to cache (only GET requests, but that’s all we have in \nthis project really). Edit the /sample route:\n@router.get(\"/sample/{n}\", response_description=\"Sample of N \ncars\")\n@cache(expire=60)\nasync def get_sample(n: int, request: Request):\n    query = [\n        {\"$match\": {\"year\": {\"$gt\": 2010}}},\n        {\n            \"$project\": {\"_id\": 0,}\n        },\n        {\"$sample\": {\"size\": n}},\n        {\"$sort\": {\"brand\": 1, \"make\": 1, \"year\": 1}},\n    ]\n    full_query = request.app.mongodb[\"cars\"].aggregate(query)\n    results = [el async for el in full_query]\n    return results\nThis route is now cached, which means that when it’s hit, it will provide a sample of size N and then, \nfor all subsequent requests in the next 60 seconds, it will send the same cached response. Go ahead \nand try it out, either on your DigitalOcean API or local environment, depending on where you \nimplemented caching. Try hitting the API for 1 minute – you should always get the same result until the \ncache expires. Congratulations – you have just added a top-of-the-class caching solution to your API!\n",
        "img": [],
        "translation": "添加 Redis 缓存\n\n291\n    app.mongodb = app.mongodb_client[DB_NAME]\n    redis = aioredis.from_url(\n        \"redis://localhost:6379\", encoding=\"utf8\", decode_responses=True\n    )\n    FastAPICache.init(RedisBackend(redis), prefix=\"fastapi-cache\")\n这段代码很容易理解 - 我们获取了一个 Redis 客户端，就像我们之前使用 Mongo 一样，并传递了 URL 和一些（建议性的）设置。最后，我们初始化了 FastAPICache。现在，我们需要在端点中添加缓存装饰器，这些端点位于 /routers/cars.py 文件中。我们将添加一个导入:\nfrom fastapi_cache.decorator import cache\n现在，我们可以装饰我们希望缓存的路由（只有 GET 请求，但实际上我们在这个项目中只需要这些）。编辑/sample 路由:\n@router.get(\"/sample/{n}\", response_description=\"Sample of N cars\")\n@cache(expire=60)\nasync def get_sample(n: int, request: Request):\n    query = [\n        {\"$match\": {\"year\": {\"$gt\": 2010}}},\n        {\n            \"$project\": {\"_id\": 0,}\n        },\n        {\"$sample\": {\"size\": n}},\n        {\"$sort\": {\"brand\": 1, \"make\": 1, \"year\": 1}},\n    ]\n    full_query = request.app.mongodb[\"cars\"].aggregate(query)\n    results = [el async for el in full_query]\n    return results\n这个路由现在被缓存了，这意味着当它被访问时，它将提供一个大小为 N 的样本，然后，在接下来的 60 秒内的所有后续请求中，它将发送相同的缓存响应。现在可以随意测试它，无论是在您的 DigitalOcean API 上还是本地环境中，具体取决于您在哪里实现了缓存。尝试在 1 分钟内访问 API - 您应该始终得到相同的结果，直到缓存过期。恭喜 - 您刚刚为您的 API 添加了一个一流的缓存解决方案！"
    },
    "14": {
        "text": "Caching with Redis and Deployment on Ubuntu (DigitalOcean) and Netlify\n292\nDeploying the Frontend on Netlify\nSimilar to Vercel, Netlify is one of the top companies providing services for static web hosting and \nserverless computing, but also a rather simple CMS and goodies such as form handling. It is widely \nregarded as one of the best solutions for hosting JAMStack websites and its content delivery network \n(CDN) can speed up the hosted websites significantly. It is also one of the easiest ways to host a React \napplication. This is what we are going to use it for in this section.\nAfter logging in with your Google or GitHub account, you will be presented with a screen that offers \nyou the possibility to deploy a new project:\nFigure 10.1 – The Netlify Add New Site button\nNext, you will be asked whether you are importing an existing project (yes!); you should choose your \nReact frontend project from GitHub. If you logged in with GitHub, you won’t have to authorize Netlify \nagain – if not, please authorize it:\nFigure 10.2 – The Import and existing project page on Netlify\n",
        "img": [
            "images/page-14-img-0.png",
            "images/page-14-img-1.png"
        ],
        "translation": "使用Redis缓存和在Ubuntu（DigitalOcean）和Netlify上部署\n292\n在Netlify上部署前端\n与Vercel类似，Netlify是提供静态Web托管和无服务器计算服务的顶级公司之一，但还提供相当简单的CMS和优惠，如表单处理。它被广泛认为是托管JAMStack网站的最佳解决方案之一，其内容交付网络（CDN）可以显着加快托管的网站速度。这也是我们在本节中要使用它的原因，来托管我们的React应用程序。\n使用您的Google或GitHub帐户登录后，您将看到一个屏幕，提供您部署新项目的可能性：\n图片10.1-Netlify添加新站点按钮\n接下来，您将被要求是否导入现有项目（是！）；您应该从GitHub选择您的React前端项目。如果您使用GitHub登录，则不必再次授权Netlify-如果没有，请授权它：\n图片10.2-Netlify上的导入现有项目页面"
    },
    "15": {
        "text": "Deploying the Frontend on Netlify\n293\nAfter browsing through your GitHub projects, point Netlify to the React frontend and leave all the \ndefaults that Netlify was able to cleverly infer from the project. You will be presented with a page on \nwhich you could potentially modify any deployment setting, but we will limit ourselves to just adding \na single environment variable. You’ve guessed it – it’s the handy REACT_APP_API_URL!\nFigure 10.3 – Netlify’s pre-deployment setting page\n",
        "img": [
            "images/page-15-img-0.png"
        ],
        "translation": "将React前端指向Netlify并保留所有Netlify能够从项目中巧妙地推断出的默认设置。您将看到一个页面，可以在该页面上修改任何部署设置，但我们将仅限于添加一个单一的环境变量。您已经猜到了——它就是方便的REACT_APP_API_URL！\n图10.3-Netlify的预部署设置页面"
    },
    "16": {
        "text": "Caching with Redis and Deployment on Ubuntu (DigitalOcean) and Netlify\n294\nYou will have to add just one variable in the advanced settings: you’ve guessed it – REACT_APP_API_\nURL. Create a New variable by hitting the respective button and name it REACT_APP_API_URL. \nThe value should be https://yourdomain.com:\nFigure 10.4 – Adding the new environment variable in Netlify\nAfter some time, maybe a minute or so, you will have your deployment ready for the world to see! In \ncase of any problems (and there will be problems), you should inspect Netlify’s deployment console \nand watch for hiccups.\nYour React frontend with all its fancy charts and fast pagination will now be served from Netlify’s fast \ncontent delivery network (CDN) while operating on a FastAPI (cached) backend served by Nginx \non DigitalOcean. Throw in our previously explored Heroku and Vercel deployments and you have a \nlot of options to start tinkering!\nThis doesn’t mean that these are your only deployment options! A popular and rock-solid choice is \nto use a Docker container and containerize your application (together or separately) and provide this \nDocker image to some of the giants – Amazon Web Services (AWS), Microsoft Azure, or Google \nApp Engine. This type of deployment isn’t much different from the Heroku deployment, although it \nrequires creating the proper type of account and setting the environment the right way. These solutions \nalso tend to have higher upfront costs.\n",
        "img": [
            "images/page-16-img-0.png"
        ],
        "translation": "使用Redis进行缓存和在Ubuntu（DigitalOcean）和Netlify上进行部署\n294\n您只需要在高级设置中添加一个变量：您猜对了 - REACT_APP_API_\nURL。按下相应的按钮创建一个新变量并将其命名为REACT_APP_API_URL。值应为https://yourdomain.com：\n图10.4-在Netlify中添加新环境变量\n经过一段时间，可能是一分钟左右，您的部署就可以向世界展示！如果出现任何问题（肯定会有问题），您应该检查Netlify的部署控制台并观察是否有问题。\n您的React前端和所有的炫酷图表及快速分页现在将由Netlify快速内容交付网络（CDN）提供服务，同时在DigitalOcean上由Nginx提供FastAPI（缓存）后端服务。加入之前探讨过的Heroku和Vercel部署，您有很多选择进行调试！\n这并不意味着这些是您唯一的部署选项！流行而坚实的选择是使用Docker容器并将应用程序（共同或分别）容器化，并向一些巨头 - 亚马逊网络服务（AWS）、Microsoft Azure或Google应用引擎提供此Docker镜像。这种部署类型与Heroku部署没有太大区别，尽管需要创建适当类型的账户并正确设置环境。这些解决方案的前期成本也更高。"
    },
    "17": {
        "text": "Summary\n295\nSummary\nIn this chapter, we added a very simple yet powerful caching solution based on Redis – an incredibly \npowerful product in its own right. We went through the tedious but often necessary procedure of \nhosting the API on a Ubuntu server behind Gunicorn and the mighty Nginx – a server that offers \nso much flexibility and configurability that it simply has to be put in the conversation of the FARM \nstack. As a bonus, we explored yet another cheap (well, free) frontend hosting option – Netlify – which \noffers premiere continuous deployment and plays very nicely with all our frontend solutions, be it \nplain React or Next.js or maybe, in the future, React-Remix. Now, you should feel confident enough \nto dive head-first into your next project and peruse the numerous options that FastAPI, React, and \nMongoDB have to offer by playing nicely with each other.\nIn the next chapter, we will try to address some of the best practices that pertain to the components of \nthe stack in every project, as well as some topics that we haven’t touched on but are equally important, \nsuch as testing, using static templates with Jinja2, site monitoring, and more.\n",
        "img": [],
        "translation": "在本章中，我们添加了一个非常简单但功能强大的基于Redis的缓存解决方案，Redis本身也是一个非常强大的产品。我们通过繁琐但经常必要的程序，在Ubuntu服务器上使用Gunicorn和强大的Nginx托管API，Nginx提供了如此多的灵活性和可配置性，以至于必须将其放在FARM堆栈的讨论中。作为一个额外的奖励，我们探索了另一个廉价（实际上是免费的）的前端托管选项Netlify，它提供了优秀的持续部署，并且与我们的所有前端解决方案非常兼容，无论是纯React、Next.js还是未来可能会用到的React-Remix。现在，您应该足够自信，可以直接跳入您的下一个项目中，通过与FastAPI、React和MongoDB的协作，探索众多可能性。\n\n在下一章中，我们将尝试解决涉及项目中每个堆栈组件的最佳实践问题，以及我们尚未涉及但同样重要的主题，例如测试、使用Jinja2的静态模板、站点监控等等。"
    }
}